{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09c3cdab",
   "metadata": {},
   "source": [
    "# 01_Amazon Nova 모델 시작하기\n",
    "\n",
    "Amazon Nova는 최첨단 품질, 뛰어난 맞춤화, 최고의 가격 대비 성능을 제공하는 새로운 세대의 멀티모달 이해 및 창의적 콘텐츠 생성 모델입니다. Amazon Nova 모델은 모든 AWS 서비스와 마찬가지로 설계부터 안전한 접근 방식을 통합하여 AI의 안전하고 책임감 있는 사용을 위한 내장 제어 기능을 갖추고 있습니다.\n",
    "\n",
    "Amazon Nova에는 두 가지 카테고리의 모델이 있습니다:\n",
    " - **이해 모델** —이러한 모델은 텍스트, 비디오, 이미지를 포함한 여러 입력 모달리티에 대해 추론할 수 있으며 텍스트를 출력합니다.\n",
    "- **창의적 콘텐츠 생성 모델** —이러한 모델은 텍스트 또는 이미지 프롬프트를 기반으로 이미지나 비디오를 생성합니다.\n",
    "  \n",
    "### Amazon Nova 모델 개요\n",
    "![media/model_intro.png](media/model_intro.png)\n",
    "\n",
    "**멀티모달 이해 모델**\n",
    "- **Amazon Nova Micro**: 번개처럼 빠른, 비용 효율적인 텍스트 전용 모델\n",
    "- **Amazon Nova Lite**: 지능 등급에서 업계에서 가장 빠르고 저렴한 멀티모달 FM\n",
    "- **Amazon Nova Pro**: 업계에서 가장 빠르고 비용 효율적이며 최첨단 멀티모달 모델\n",
    "\n",
    "**창의적 콘텐츠 생성 모델**\n",
    "- **Amazon Nova Canvas**: 최첨단 이미지 생성 모델\n",
    "- **Amazon Nova Reel**: 최첨단 비디오 생성 모델\n",
    "\n",
    "\n",
    "다음 노트북은 주로 Amazon Nova 이해 모델에 초점을 맞출 것입니다.\n",
    "\n",
    "**Amazon Nova 멀티모달 이해** 기반 모델(FM)은 텍스트, 비디오, 문서 및/또는 이미지를 포함한 여러 입력 모달리티에 대해 추론하고 텍스트를 출력할 수 있는 모델 제품군입니다. Bedrock Converse API 및 InvokeModel API를 통해 이러한 모델에 액세스할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aea9407",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 1. 설정\n",
    "\n",
    "**1단계: 모델 액세스 권한 얻기**: Bedrock에서 아직 모델 액세스를 요청하지 않았다면 [이 지침에 따라 액세스 요청](https://docs.aws.amazon.com/bedrock/latest/userguide/model-access-modify.html)을 할 수 있습니다.\n",
    "\n",
    "![media/model_access.png](media/model_access.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c633ddd-299c-4fb6-98ba-b01bb8b48f50",
   "metadata": {},
   "source": [
    "## 2 언제 무엇을 사용해야 할까요?\n",
    "\n",
    "## 2.1 Amazon Nova Micro 모델을 사용해야 할 때\n",
    "\n",
    "Amazon Nova Micro(텍스트 입력만 가능)는 가장 빠르고 저렴한 옵션으로, 대화형 인터페이스, 채팅 및 분류, 라우팅, 엔티티 추출, 문서 요약과 같은 대규모 지연 시간에 민감한 배포에 최적화되어 있습니다.\n",
    "\n",
    "## 2.2 Amazon Nova Lite 모델을 사용해야 할 때\n",
    "\n",
    "Amazon Nova Lite는 지능, 지연 시간 및 비용 효율성의 균형을 맞춥니다. 여러 도구 호출을 동시에 조율해야 하는 대화형 에이전트와 같이 낮은 지연 시간(최소 지연)이 중요한 복잡한 시나리오에 최적화되어 있습니다. Amazon Nova Lite는 이미지, 비디오 및 텍스트 입력을 지원하고 텍스트를 출력합니다.\n",
    "\n",
    "## 2.3 Amazon Nova Pro 모델을 사용해야 할 때\n",
    "Amazon Nova Pro는 고급 추론, 창의성 및 코드 생성이 필요한 매우 복잡한 사용 사례를 위해 설계되었습니다. Amazon Nova Pro는 이미지, 비디오 및 텍스트 입력을 지원하고 텍스트를 출력합니다.\n",
    "\n",
    "---\n",
    "\n",
    "## 사전 요구 사항\n",
    "\n",
    "이 워크숍의 노트북에 필요한 패키지를 설치하기 위해 이 섹션의 셀을 실행하세요. ⚠️ pip 종속성 오류가 표시되지만 이러한 오류는 안전하게 무시할 수 있습니다. ⚠️\n",
    "\n",
    "_오류 무시: pip의 종속성 해결 프로그램은 현재 설치된 모든 패키지를 고려하지 않습니다. 이 동작은 다음 종속성 충돌의 원인입니다._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1effee7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting boto3>=1.28.57\n",
      "  Downloading boto3-1.37.28-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting awscli>=1.29.57\n",
      "  Downloading awscli-1.38.28-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting botocore>=1.31.57\n",
      "  Downloading botocore-1.37.28-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting jmespath<2.0.0,>=0.7.1 (from boto3>=1.28.57)\n",
      "  Using cached jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting s3transfer<0.12.0,>=0.11.0 (from boto3>=1.28.57)\n",
      "  Downloading s3transfer-0.11.4-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting docutils<0.17,>=0.10 (from awscli>=1.29.57)\n",
      "  Using cached docutils-0.16-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting PyYAML<6.1,>=3.10 (from awscli>=1.29.57)\n",
      "  Using cached PyYAML-6.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting colorama<0.4.7,>=0.2.5 (from awscli>=1.29.57)\n",
      "  Using cached colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
      "Collecting rsa<4.8,>=3.1.2 (from awscli>=1.29.57)\n",
      "  Using cached rsa-4.7.2-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting python-dateutil<3.0.0,>=2.1 (from botocore>=1.31.57)\n",
      "  Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting urllib3!=2.2.0,<3,>=1.25.4 (from botocore>=1.31.57)\n",
      "  Using cached urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting six>=1.5 (from python-dateutil<3.0.0,>=2.1->botocore>=1.31.57)\n",
      "  Using cached six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting pyasn1>=0.1.3 (from rsa<4.8,>=3.1.2->awscli>=1.29.57)\n",
      "  Using cached pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Downloading boto3-1.37.28-py3-none-any.whl (139 kB)\n",
      "Downloading awscli-1.38.28-py3-none-any.whl (4.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m180.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading botocore-1.37.28-py3-none-any.whl (13.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m252.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Using cached colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Using cached docutils-0.16-py2.py3-none-any.whl (548 kB)\n",
      "Using cached jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "Using cached PyYAML-6.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (751 kB)\n",
      "Using cached rsa-4.7.2-py3-none-any.whl (34 kB)\n",
      "Downloading s3transfer-0.11.4-py3-none-any.whl (84 kB)\n",
      "Using cached urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
      "Using cached pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Using cached six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
      "Installing collected packages: urllib3, six, PyYAML, pyasn1, jmespath, docutils, colorama, rsa, python-dateutil, botocore, s3transfer, boto3, awscli\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 2.3.0\n",
      "    Uninstalling urllib3-2.3.0:\n",
      "      Successfully uninstalled urllib3-2.3.0\n",
      "  Attempting uninstall: six\n",
      "    Found existing installation: six 1.17.0\n",
      "    Uninstalling six-1.17.0:\n",
      "      Successfully uninstalled six-1.17.0\n",
      "  Attempting uninstall: PyYAML\n",
      "    Found existing installation: PyYAML 6.0.2\n",
      "    Uninstalling PyYAML-6.0.2:\n",
      "      Successfully uninstalled PyYAML-6.0.2\n",
      "  Attempting uninstall: pyasn1\n",
      "    Found existing installation: pyasn1 0.6.1\n",
      "    Uninstalling pyasn1-0.6.1:\n",
      "      Successfully uninstalled pyasn1-0.6.1\n",
      "  Attempting uninstall: jmespath\n",
      "    Found existing installation: jmespath 1.0.1\n",
      "    Uninstalling jmespath-1.0.1:\n",
      "      Successfully uninstalled jmespath-1.0.1\n",
      "  Attempting uninstall: docutils\n",
      "    Found existing installation: docutils 0.16\n",
      "    Uninstalling docutils-0.16:\n",
      "      Successfully uninstalled docutils-0.16\n",
      "  Attempting uninstall: colorama\n",
      "    Found existing installation: colorama 0.4.6\n",
      "    Uninstalling colorama-0.4.6:\n",
      "      Successfully uninstalled colorama-0.4.6\n",
      "  Attempting uninstall: rsa\n",
      "    Found existing installation: rsa 4.7.2\n",
      "    Uninstalling rsa-4.7.2:\n",
      "      Successfully uninstalled rsa-4.7.2\n",
      "  Attempting uninstall: python-dateutil\n",
      "    Found existing installation: python-dateutil 2.9.0.post0\n",
      "    Uninstalling python-dateutil-2.9.0.post0:\n",
      "      Successfully uninstalled python-dateutil-2.9.0.post0\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.36.24\n",
      "    Uninstalling botocore-1.36.24:\n",
      "      Successfully uninstalled botocore-1.36.24\n",
      "  Attempting uninstall: s3transfer\n",
      "    Found existing installation: s3transfer 0.11.2\n",
      "    Uninstalling s3transfer-0.11.2:\n",
      "      Successfully uninstalled s3transfer-0.11.2\n",
      "  Attempting uninstall: boto3\n",
      "    Found existing installation: boto3 1.36.24\n",
      "    Uninstalling boto3-1.36.24:\n",
      "      Successfully uninstalled boto3-1.36.24\n",
      "  Attempting uninstall: awscli\n",
      "    Found existing installation: awscli 1.37.24\n",
      "    Uninstalling awscli-1.37.24:\n",
      "      Successfully uninstalled awscli-1.37.24\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "jupyter-server 2.15.0 requires packaging>=22.0, but you have packaging 21.3 which is incompatible.\n",
      "sphinx 8.1.3 requires docutils<0.22,>=0.20, but you have docutils 0.16 which is incompatible.\n",
      "sphinx 8.1.3 requires packaging>=23.0, but you have packaging 21.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed PyYAML-6.0.2 awscli-1.38.28 boto3-1.37.28 botocore-1.37.28 colorama-0.4.6 docutils-0.16 jmespath-1.0.1 pyasn1-0.6.1 python-dateutil-2.9.0.post0 rsa-4.7.2 s3transfer-0.11.4 six-1.17.0 urllib3-2.3.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --no-build-isolation --force-reinstall \\\n",
    "    \"boto3>=1.28.57\" \\\n",
    "    \"awscli>=1.29.57\" \\\n",
    "    \"botocore>=1.31.57\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cfe86f9-b9d3-4d10-b4c6-d80f38d52b83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>Jupyter.notebook.kernel.restart()</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# restart kernel\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"<script>Jupyter.notebook.kernel.restart()</script>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e9d37a",
   "metadata": {},
   "source": [
    "### 2. 텍스트 이해 [Amazon Nova Micro, Amazon Nova Lite, Amazon Nova Pro에 적용 가능]\n",
    "\n",
    "아래 예제는 간단한 시스템 프롬프트와 메시지 목록을 포함한 텍스트 기반 프롬프트를 사용하는 방법을 보여줍니다.\n",
    "\n",
    "\n",
    "참고: 아래 예제는 설명 목적으로 Nova Lite를 사용하고 있지만 텍스트 이해 사용 사례에 Micro 모델을 사용할 수도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32dd0c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import base64\n",
    "from datetime import datetime\n",
    "\n",
    "PRO_MODEL_ID = \"us.amazon.nova-pro-v1:0\"\n",
    "LITE_MODEL_ID = \"us.amazon.nova-lite-v1:0\"\n",
    "MICRO_MODEL_ID = \"us.amazon.nova-micro-v1:0\"\n",
    "\n",
    "# Create a Bedrock Runtime client in the AWS Region of your choice.\n",
    "client = boto3.client(\"bedrock-runtime\", region_name=\"us-east-1\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e62778-e5f5-4664-a81c-ac27b54d3c2c",
   "metadata": {},
   "source": [
    "### InvokeModel 본문 및 출력\n",
    "\n",
    "Amazon Bedrock 런타임 클라이언트의 invoke_model() 메서드(InvokeModel API)는 대부분의 텍스트 생성 및 처리 작업에 사용할 주요 메서드입니다.\n",
    "\n",
    "메서드는 공유되지만 입력 및 출력 형식은 아래 설명된 대로 사용되는 기반 모델에 따라 다릅니다:\n",
    "\n",
    "\n",
    "```python\n",
    "{\n",
    "  \"system\": [\n",
    "    {\n",
    "      \"text\": string\n",
    "    }\n",
    "  ],\n",
    "  \"messages\": [\n",
    "    {\n",
    "      \"role\": \"user\",# 첫 번째 턴은 항상 사용자 턴이어야 함\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"text\": string\n",
    "        },\n",
    "        {\n",
    "          \"image\": {\n",
    "            \"format\": \"jpeg\"| \"png\" | \"gif\" | \"webp\",\n",
    "            \"source\": {\n",
    "              \"bytes\": \"base64EncodedImageDataHere...\"#  base64로 인코딩된 바이너리\n",
    "            }\n",
    "          }\n",
    "        },\n",
    "        {\n",
    "          \"video\": {\n",
    "            \"format\": \"mkv\" | \"mov\" | \"mp4\" | \"webm\" | \"three_gp\" | \"flv\" | \"mpeg\" | \"mpg\" | \"wmv\",\n",
    "            \"source\": {\n",
    "            # 소스는 입력 파일 크기에 따라 s3 위치 또는 base64 바이트가 될 수 있습니다. \n",
    "               \"s3Location\": {\n",
    "                \"uri\": string, #  예: s3://my-bucket/object-key\n",
    "                \"bucketOwner\": string #  (선택 사항) 예: 123456789012)\n",
    "               }\n",
    "              \"bytes\": \"base64EncodedImageDataHere...\" #  base64로 인코딩된 바이너리\n",
    "            }\n",
    "          }\n",
    "        },\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"assistant\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"text\": string # 어시스턴트 턴 미리 채우기\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ],\n",
    " \"inferenceConfig\":{ # 모두 선택 사항\n",
    "    \"max_new_tokens\": int, #  0보다 크고 5k 이하 (기본값: 동적*)\n",
    "    \"temperature\": float, # 0보다 크고 1.0 미만 (기본값: 0.7)\n",
    "    \"top_p\": float, #  0보다 크고 1.0 이하 (기본값: 0.9)\n",
    "    \"top_k\": int #  0 이상 (기본값: 50)\n",
    "    \"stopSequences\": [string]\n",
    "  },\n",
    "  \"toolConfig\": { #  모두 선택 사항\n",
    "        \"tools\": [\n",
    "                {\n",
    "                    \"toolSpec\": {\n",
    "                        \"name\": string # 의미 있는 도구 이름 (최대 문자: 64)\n",
    "                        \"description\": string # 도구에 대한 의미 있는 설명\n",
    "                        \"inputSchema\": {\n",
    "                            \"json\": { # 도구의 JSON 스키마. 자세한 내용은 JSON 스키마 참조를 참조하세요\n",
    "                                \"type\": \"object\",\n",
    "                                \"properties\": {\n",
    "                                    <args>: { # 인수 \n",
    "                                        \"type\": string, # 인수 데이터 유형\n",
    "                                        \"description\": string # 의미 있는 설명\n",
    "                                    }\n",
    "                                },\n",
    "                                \"required\": [\n",
    "                                    string # args\n",
    "                                ]\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            ],\n",
    "   \"toolChoice\": \"auto\" [\"auto\" | \"any\" | \"tool\" ]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "다음은 필수 매개변수입니다.\n",
    "\n",
    "* `system` – (선택 사항) 요청에 대한 시스템 프롬프트.\n",
    "    시스템 프롬프트는 특정 목표나 역할을 지정하는 등 Amazon Nova에 컨텍스트와 지침을 제공하는 방법입니다.\n",
    "* `messages` – (필수) 입력 메시지.\n",
    "    * `role` – 대화 턴의 역할. 유효한 값은 user와 assistant입니다. \n",
    "    * `content` – (필수) 대화 턴의 내용.\n",
    "        * `type` – (필수) 콘텐츠의 유형. 유효한 값은 image, text, video입니다.\n",
    "            * text를 선택한 경우 (텍스트 콘텐츠)\n",
    "                * `text` - 대화 턴의 내용. \n",
    "            * Image를 선택한 경우 (이미지 콘텐츠)\n",
    "                * `source` – (필수) 이미지에 대한 base64로 인코딩된 이미지 바이트.\n",
    "                * `format` – (필수) 이미지의 유형. 다음 이미지 형식을 지정할 수 있습니다. \n",
    "                    * `jpeg`\n",
    "                    * `png`\n",
    "                    * `webp`\n",
    "                    * `gif`\n",
    "            * video를 선택한 경우: (비디오 콘텐츠)\n",
    "                * `source` – (필수) 비디오에 대한 base64로 인코딩된 이미지 바이트 또는 위 스키마에 표시된 S3 URI 및 버킷 소유자\n",
    "                * `format` – (필수) 비디오의 유형. 다음 비디오 형식을 지정할 수 있습니다. \n",
    "                    * `mkv`\n",
    "                    *  `mov`  \n",
    "                    *  `mp4`\n",
    "                    *  `webm`\n",
    "                    *  `three_gp`\n",
    "                    *  `flv`  \n",
    "                    *  `mpeg`  \n",
    "                    *  `mpg`\n",
    "                    *  `wmv`\n",
    "* `inferenceConfig`: 추론에 전달할 수 있는 추론 구성 값입니다.\n",
    "    * `max_new_tokens` – (선택 사항) 생성을 중지하기 전에 생성할 최대 토큰 수.\n",
    "        Amazon Nova 모델은 max_tokens 값에 도달하기 전에 토큰 생성을 중지할 수 있습니다. 허용되는 최대 새 토큰 값은 5K입니다.\n",
    "    * `temperature` – (선택 사항) 응답에 주입되는 무작위성의 양.\n",
    "    * `top_p` – (선택 사항) 핵 샘플링 사용. Amazon Nova는 확률이 감소하는 순서로 각 후속 토큰에 대한 모든 옵션의 누적 분포를 계산하고 top_p에 의해 지정된 특정 확률에 도달하면 중단합니다. temperature 또는 top_p 중 하나만 변경해야 하며 둘 다 변경하지 마세요.\n",
    "    * `top_k` – (선택 사항) 각 후속 토큰에 대해 상위 K 옵션에서만 샘플링합니다. top_k를 사용하여 확률이 낮은 긴 꼬리 응답을 제거합니다.\n",
    "    * `stopSequences` – (선택 사항) 중지 시퀀스가 포함된 문자열 배열. 모델이 이러한 문자열 중 하나를 생성하면 생성이 중지되고 해당 지점까지의 응답이 반환됩니다. \n",
    "    * `toolConfig` – (선택 사항) ToolConfig 스키마를 따르는 JSON 객체로, 도구 사양과 도구 선택이 포함됩니다. 이 스키마는 Converse API가 따르는 것과 동일합니다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a9f067",
   "metadata": {},
   "source": [
    "#### 2.1 동기식 API 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "353f4769-4397-4dae-a4de-8a295569f6fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request ID: 06d440c1-8338-453a-967d-4082f9d6ec2c\n",
      "\n",
      "[Full Response]\n",
      "{\n",
      "  \"output\": {\n",
      "    \"message\": {\n",
      "      \"content\": [\n",
      "        {\n",
      "          \"text\": \"\\ubb3c\\uace0\\uae30\\uac00 \\ubc14\\ub2e4\\uc5d0\\uc11c \\ub2e4\\ub978 \\ubb3c\\uace0\\uae30\\uc5d0\\uac8c \\ub9d0\\ud588\\ub2e4: \\\"\\uc624\\ub298 \\ub0a0\\uc528 \\uc5b4\\ub54c?\\\" \\ub2e4\\ub978 \\ubb3c\\uace0\\uae30\\uac00 \\ub300\\ub2f5\\ud588\\ub2e4: \\\"\\ub098\\ub294 \\ubb3c \\uc18d\\uc5d0 \\uc788\\uc5b4\\uc11c \\ub0a0\\uc528\\uc5d0 \\ub300\\ud574 \\ubab0\\ub77c.\\\" \\uc6c3\\uaca8, \\ub9de\\uc9c0?\"\n",
      "        }\n",
      "      ],\n",
      "      \"role\": \"assistant\"\n",
      "    }\n",
      "  },\n",
      "  \"stopReason\": \"end_turn\",\n",
      "  \"usage\": {\n",
      "    \"inputTokens\": 13,\n",
      "    \"outputTokens\": 103,\n",
      "    \"totalTokens\": 116,\n",
      "    \"cacheReadInputTokenCount\": 0,\n",
      "    \"cacheWriteInputTokenCount\": 0\n",
      "  }\n",
      "}\n",
      "\n",
      "[Response Content Text]\n",
      "물고기가 바다에서 다른 물고기에게 말했다: \"오늘 날씨 어때?\" 다른 물고기가 대답했다: \"나는 물 속에 있어서 날씨에 대해 몰라.\" 웃겨, 맞지?\n"
     ]
    }
   ],
   "source": [
    "# Define your system prompt(s).\n",
    "system_list = [\n",
    "    { \"text\": \"You should respond to all messages in korean only\" }\n",
    "]\n",
    "\n",
    "# Define one or more messages using the \"user\" and \"assistant\" roles.\n",
    "message_list = [\n",
    "    {\"role\": \"user\", \"content\": [{\"text\": \"tell me a joke\"}]},\n",
    "]\n",
    "\n",
    "# Configure the inference parameters.\n",
    "inf_params = {\"max_new_tokens\": 300, \"top_p\": 0.9, \"top_k\": 20, \"temperature\": 0.7}\n",
    "\n",
    "native_request = {\n",
    "    \"messages\": message_list,\n",
    "    \"system\": system_list,\n",
    "    \"inferenceConfig\": inf_params,\n",
    "}\n",
    "\n",
    "# Invoke the model and extract the response body.\n",
    "response = client.invoke_model(modelId=LITE_MODEL_ID, body=json.dumps(native_request))\n",
    "request_id = response[\"ResponseMetadata\"][\"RequestId\"]\n",
    "print(f\"Request ID: {request_id}\")\n",
    "model_response = json.loads(response[\"body\"].read())\n",
    "\n",
    "# Pretty print the response JSON.\n",
    "print(\"\\n[Full Response]\")\n",
    "print(json.dumps(model_response, indent=2))\n",
    "\n",
    "# Print the text content for easy readability.\n",
    "content_text = model_response[\"output\"][\"message\"][\"content\"][0][\"text\"]\n",
    "print(\"\\n[Response Content Text]\")\n",
    "print(content_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9926bc",
   "metadata": {},
   "source": [
    "#### 2.2 스트리밍 API 호출\n",
    "\n",
    "아래 예제는 스트리밍 API와 함께 텍스트 기반 프롬프트를 사용하는 방법을 보여줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4728b5e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request ID: ccdcb038-98e1-4435-af93-f82aedbb3e57\n",
      "Awaiting first token...\n",
      "Time to first token: 0:00:00.200032\n",
      "래 캠핑을 하던 그날, 불빛에 웃으며 따뜻한 커피를 마셨다. 밤하늘에는 별들이 춤을 추고, 숲 속에서 들려오는 소리들이 마법 같았다.\n",
      "Total chunks: 34\n",
      "-----------\n",
      "별빛 아래 캠핑을 하던 그날, 불빛에 웃으며 따뜻한 커피를 마셨다. 밤하늘에는 별들이 춤을 추고, 숲 속에서 들려오는 소리들이 마법 같았다.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define your system prompt(s).\n",
    "system_list = [\n",
    "    { \"text\": \"Act as a creative writing assistant. When the user provides you with a topic, write a 20~30 words Korean story about that topic\" }\n",
    "]\n",
    "\n",
    "# Define one or more messages using the \"user\" and \"assistant\" roles.\n",
    "message_list = [{\"role\": \"user\", \"content\": [{\"text\": \"캠핑\"}]}]\n",
    "\n",
    "# Configure the inference parameters.\n",
    "inf_params = {\"max_new_tokens\": 1000, \"top_p\": 0.9, \"top_k\": 20, \"temperature\": 0.7}\n",
    "\n",
    "request_body = {\n",
    "    \"messages\": message_list,\n",
    "    \"system\": system_list,\n",
    "    \"inferenceConfig\": inf_params,\n",
    "}\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "# Invoke the model with the response stream\n",
    "response = client.invoke_model_with_response_stream(\n",
    "    modelId=LITE_MODEL_ID, body=json.dumps(request_body)\n",
    ")\n",
    "\n",
    "request_id = response.get(\"ResponseMetadata\").get(\"RequestId\")\n",
    "print(f\"Request ID: {request_id}\")\n",
    "print(\"Awaiting first token...\")\n",
    "\n",
    "chunk_count = 0\n",
    "time_to_first_token = None\n",
    "full_response = \"\"\n",
    "\n",
    "# Process the response stream\n",
    "stream = response.get(\"body\")\n",
    "if stream:\n",
    "    for event in stream:\n",
    "        chunk = event.get(\"chunk\")\n",
    "        if chunk:\n",
    "            # Print the response chunk\n",
    "            chunk_json = json.loads(chunk.get(\"bytes\").decode())\n",
    "            # Pretty print JSON\n",
    "            # print(json.dumps(chunk_json, indent=2, ensure_ascii=False))\n",
    "            content_block_delta = chunk_json.get(\"contentBlockDelta\")\n",
    "            if content_block_delta:\n",
    "                if time_to_first_token is None:\n",
    "                    time_to_first_token = datetime.now() - start_time\n",
    "                    print(f\"Time to first token: {time_to_first_token}\")\n",
    "\n",
    "                chunk_count += 1\n",
    "                current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S:%f\")\n",
    "                # print(f\"{current_time} - \", end=\"\")\n",
    "                text = content_block_delta.get(\"delta\").get(\"text\")\n",
    "                full_response += text\n",
    "                print(text, end=\"\")\n",
    "    print(f\"\\nTotal chunks: {chunk_count}\")\n",
    "else:\n",
    "    print(\"No response stream received.\")\n",
    "\n",
    "print(\"-----------\")\n",
    "print(full_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c25e1a9-912e-4bb5-82ef-9b3f673bd215",
   "metadata": {},
   "source": [
    "### 3. 멀티모달 이해 [Amazon Nova lite/Amazon Nova Pro 모델에만 적용 가능]\n",
    "\n",
    "다음 예제는 모델에 다양한 미디어 유형을 전달하는 방법을 보여줍니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0239ff-e022-462f-b44d-b6d840ceade5",
   "metadata": {},
   "source": [
    "#### 3.1 이미지 이해\n",
    "\n",
    "Nova 모델이 이미지 이해 사용 사례에서 어떻게 작동하는지 살펴보겠습니다.\n",
    "\n",
    "여기서는 일몰 이미지를 전달하고 모델에게 이 이미지에 대한 3가지 예술 제목을 만들어 보라고 요청하겠습니다.\n",
    "\n",
    "![일몰 이미지](media/sunset.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e01e09ea-112d-4cfd-a778-b06f6477be85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Full Response]\n",
      "{\n",
      "  \"output\": {\n",
      "    \"message\": {\n",
      "      \"content\": [\n",
      "        {\n",
      "          \"text\": \"1. \\ud574\\ub3cb\\uc774 \\ud48d\\uacbd (Sunrise Landscape)\\n2. \\ud638\\uc218\\uc758 \\ud669\\ud63c (Twilight by the Lake)\\n3. \\ub099\\uc870\\uc758 \\uc544\\ub984\\ub2e4\\uc6c0 (Beauty of the Setting Sun)\"\n",
      "        }\n",
      "      ],\n",
      "      \"role\": \"assistant\"\n",
      "    }\n",
      "  },\n",
      "  \"stopReason\": \"end_turn\",\n",
      "  \"usage\": {\n",
      "    \"inputTokens\": 1344,\n",
      "    \"outputTokens\": 62,\n",
      "    \"totalTokens\": 1406,\n",
      "    \"cacheReadInputTokenCount\": 0,\n",
      "    \"cacheWriteInputTokenCount\": 0\n",
      "  }\n",
      "}\n",
      "\n",
      "[Response Content Text]\n",
      "1. 해돋이 풍경 (Sunrise Landscape)\n",
      "2. 호수의 황혼 (Twilight by the Lake)\n",
      "3. 낙조의 아름다움 (Beauty of the Setting Sun)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Open the image you'd like to use and encode it as a Base64 string.\n",
    "with open(\"media/sunset.png\", \"rb\") as image_file:\n",
    "    binary_data = image_file.read()\n",
    "    base_64_encoded_data = base64.b64encode(binary_data)\n",
    "    base64_string = base_64_encoded_data.decode(\"utf-8\")\n",
    "\n",
    "# Define your system prompt(s).\n",
    "system_list = [\n",
    "    { \"text\": \"You are an expert artist. When the user provides you with an image, provide 3 potential art titles in Korean\" }\n",
    "]\n",
    "\n",
    "# Define a \"user\" message including both the image and a text prompt.\n",
    "message_list = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"image\": {\n",
    "                    \"format\": \"png\",\n",
    "                    \"source\": {\"bytes\": base64_string},\n",
    "                }\n",
    "            },\n",
    "            {\"text\": \"Provide art titles for this image.\"},\n",
    "        ],\n",
    "    }\n",
    "]\n",
    "\n",
    "# Configure the inference parameters.\n",
    "inf_params = {\"max_new_tokens\": 300, \"top_p\": 0.1, \"top_k\": 20, \"temperature\": 0.3}\n",
    "\n",
    "native_request = {\n",
    "    \"messages\": message_list,\n",
    "    \"system\": system_list,\n",
    "    \"inferenceConfig\": inf_params,\n",
    "}\n",
    "\n",
    "# Invoke the model and extract the response body.\n",
    "response = client.invoke_model(modelId=LITE_MODEL_ID, body=json.dumps(native_request))\n",
    "model_response = json.loads(response[\"body\"].read())\n",
    "\n",
    "# Pretty print the response JSON.\n",
    "print(\"[Full Response]\")\n",
    "print(json.dumps(model_response, indent=2))\n",
    "\n",
    "# Print the text content for easy readability.\n",
    "content_text = model_response[\"output\"][\"message\"][\"content\"][0][\"text\"]\n",
    "print(\"\\n[Response Content Text]\")\n",
    "print(content_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12c7267",
   "metadata": {},
   "source": [
    "여러 이미지 콘텐츠가 있을 수 있습니다. 이 예제에서는 모델에게 두 이미지의 공통점을 찾아보라고 요청합니다:\n",
    "\n",
    "![](media/cat.jpeg)\n",
    "\n",
    "![](media/dog.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "90b13815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Full Response]\n",
      "{\n",
      "  \"output\": {\n",
      "    \"message\": {\n",
      "      \"content\": [\n",
      "        {\n",
      "          \"text\": \"\\uc774 \\ub450 \\uc774\\ubbf8\\uc9c0\\uc758 \\uacf5\\ud1b5\\uc810\\uc740 \\ubaa8\\ub450 \\ubc18\\ub824\\ub3d9\\ubb3c\\uc744 \\uc18c\\uc7ac\\ub85c \\ud55c\\ub2e4\\ub294 \\uc810\\uc785\\ub2c8\\ub2e4. \\uccab \\ubc88\\uc9f8 \\uc774\\ubbf8\\uc9c0\\ub294 \\uac80\\uc740\\uc0c9\\uacfc \\ud770\\uc0c9\\uc758 \\uac1c\\ub97c \\ubcf4\\uc5ec\\uc8fc\\uace0, \\ub450 \\ubc88\\uc9f8 \\uc774\\ubbf8\\uc9c0\\ub294 \\ud68c\\uc0c9\\uacfc \\ud770\\uc0c9\\uc758 \\uace0\\uc591\\uc774\\ub97c \\ubcf4\\uc5ec\\uc90d\\ub2c8\\ub2e4. \\ub450 \\uc774\\ubbf8\\uc9c0 \\ubaa8\\ub450 \\ubc18\\ub824\\ub3d9\\ubb3c\\uc758 \\ub208\\uc744 \\uac15\\uc870\\ud558\\uace0 \\uc788\\uc73c\\uba70, \\uac1c\\ub294 \\uc785\\uc744 \\ubc8c\\ub9ac\\uace0 \\ud600\\ub97c \\ub0b4\\ubc00\\uace0 \\uc788\\uc73c\\uba70, \\uace0\\uc591\\uc774\\ub294 \\ub208\\uc744 \\ud06c\\uac8c \\ub728\\uace0 \\uc788\\uc2b5\\ub2c8\\ub2e4. \\ub450 \\uc774\\ubbf8\\uc9c0 \\ubaa8\\ub450 \\ubc18\\ub824\\ub3d9\\ubb3c\\uc758 \\uadc0\\uc5ec\\uc6c0\\uacfc \\ub9e4\\ub825\\uc744 \\uac15\\uc870\\ud558\\uace0 \\uc788\\uc2b5\\ub2c8\\ub2e4.\"\n",
      "        }\n",
      "      ],\n",
      "      \"role\": \"assistant\"\n",
      "    }\n",
      "  },\n",
      "  \"stopReason\": \"end_turn\",\n",
      "  \"usage\": {\n",
      "    \"inputTokens\": 3548,\n",
      "    \"outputTokens\": 226,\n",
      "    \"totalTokens\": 3774,\n",
      "    \"cacheReadInputTokenCount\": 0,\n",
      "    \"cacheWriteInputTokenCount\": 0\n",
      "  }\n",
      "}\n",
      "\n",
      "[Response Content Text]\n",
      "이 두 이미지의 공통점은 모두 반려동물을 소재로 한다는 점입니다. 첫 번째 이미지는 검은색과 흰색의 개를 보여주고, 두 번째 이미지는 회색과 흰색의 고양이를 보여줍니다. 두 이미지 모두 반려동물의 눈을 강조하고 있으며, 개는 입을 벌리고 혀를 내밀고 있으며, 고양이는 눈을 크게 뜨고 있습니다. 두 이미지 모두 반려동물의 귀여움과 매력을 강조하고 있습니다.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Open the image you'd like to use and encode it as a Base64 string.\n",
    "with open(\"media/dog.jpeg\", \"rb\") as image_file:\n",
    "    binary_data = image_file.read()\n",
    "    base_64_encoded_data = base64.b64encode(binary_data)\n",
    "    dog_base64_string = base_64_encoded_data.decode(\"utf-8\")\n",
    "\n",
    "with open(\"media/cat.jpeg\", \"rb\") as image_file:\n",
    "    binary_data = image_file.read()\n",
    "    base_64_encoded_data = base64.b64encode(binary_data)\n",
    "    cat_base64_string = base_64_encoded_data.decode(\"utf-8\")\n",
    "\n",
    "# Define a \"user\" message including both the image and a text prompt.\n",
    "message_list = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"image\": {\n",
    "                    \"format\": \"jpeg\",\n",
    "                    \"source\": {\"bytes\": dog_base64_string},\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"image\": {\n",
    "                    \"format\": \"jpeg\",\n",
    "                    \"source\": {\"bytes\": cat_base64_string},\n",
    "                }\n",
    "            },\n",
    "            {\"text\": \"What do these two images have in common? Response in Korean.\"},\n",
    "        ],\n",
    "    }\n",
    "]\n",
    "\n",
    "# Configure the inference parameters.\n",
    "inf_params = {\"max_new_tokens\": 300, \"top_p\": 0.1, \"top_k\": 20, \"temperature\": 0.3}\n",
    "\n",
    "native_request = {\n",
    "    \"messages\": message_list,\n",
    "    \"inferenceConfig\": inf_params,\n",
    "}\n",
    "\n",
    "# Invoke the model and extract the response body.\n",
    "response = client.invoke_model(modelId=PRO_MODEL_ID, body=json.dumps(native_request))\n",
    "model_response = json.loads(response[\"body\"].read())\n",
    "\n",
    "# Pretty print the response JSON.\n",
    "print(\"[Full Response]\")\n",
    "print(json.dumps(model_response, indent=2))\n",
    "\n",
    "# Print the text content for easy readability.\n",
    "content_text = model_response[\"output\"][\"message\"][\"content\"][0][\"text\"]\n",
    "print(\"\\n[Response Content Text]\")\n",
    "print(content_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2976fe-29dc-477b-b27a-758f8f450a05",
   "metadata": {},
   "source": [
    "#### 3.2 비디오 이해"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c0de24-c4cf-497c-b6a7-d38b7c6b963e",
   "metadata": {},
   "source": [
    "이제 Nova가 비디오 이해 사용 사례에서 어떻게 작동하는지 살펴보겠습니다.\n",
    "\n",
    "여기서는 케사디야 만들기 지침이 담긴 비디오를 전달할 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d7f9a327-79b2-472b-911e-735546aa51bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"media/the-sea.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Video\n",
    "\n",
    "Video(\"media/the-sea.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9253bf6e-b2dc-41ef-ae5f-b06e35568eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Full Response]\n",
      "{\n",
      "  \"output\": {\n",
      "    \"message\": {\n",
      "      \"content\": [\n",
      "        {\n",
      "          \"text\": \"\\ubb3c\\ub860\\uc785\\ub2c8\\ub2e4. \\uc601\\uc0c1\\uc5d0 \\uc5b4\\uc6b8\\ub9ac\\ub294 \\uc81c\\ubaa9\\uc744 \\uc138 \\uac00\\uc9c0 \\ub9cc\\ub4e4\\uc5b4 \\ubcf4\\uc558\\uc2b5\\ub2c8\\ub2e4.\\n\\n1.  \\ubc14\\ub2e4\\uc758 \\uc544\\ub984\\ub2e4\\uc6c0: \\uc808\\uacbd\\uacfc \\uc870\\uac1c\\uc758 \\uc870\\ud654\\n2.  \\ud0dc\\ud3c9\\uc591 \\uc5f0\\uc548\\uc758 \\uc790\\uc5f0\\ubbf8: \\uc554\\ucd08\\uc640 \\uc870\\uac1c\\uc758 \\uc774\\uc57c\\uae30\\n3.  \\ubc14\\ub2e4 \\ud48d\\uacbd: \\uc808\\ubcbd, \\uc554\\ucd08, \\uadf8\\ub9ac\\uace0 \\uc870\\uac1c\"\n",
      "        }\n",
      "      ],\n",
      "      \"role\": \"assistant\"\n",
      "    }\n",
      "  },\n",
      "  \"stopReason\": \"end_turn\",\n",
      "  \"usage\": {\n",
      "    \"inputTokens\": 3509,\n",
      "    \"outputTokens\": 138,\n",
      "    \"totalTokens\": 3647,\n",
      "    \"cacheReadInputTokenCount\": 0,\n",
      "    \"cacheWriteInputTokenCount\": 0\n",
      "  }\n",
      "}\n",
      "\n",
      "[Response Content Text]\n",
      "물론입니다. 영상에 어울리는 제목을 세 가지 만들어 보았습니다.\n",
      "\n",
      "1.  바다의 아름다움: 절경과 조개의 조화\n",
      "2.  태평양 연안의 자연미: 암초와 조개의 이야기\n",
      "3.  바다 풍경: 절벽, 암초, 그리고 조개\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Open the image you'd like to use and encode it as a Base64 string.\n",
    "with open(\"media/the-sea.mp4\", \"rb\") as video_file:\n",
    "    binary_data = video_file.read()\n",
    "    base_64_encoded_data = base64.b64encode(binary_data)\n",
    "    base64_string = base_64_encoded_data.decode(\"utf-8\")\n",
    "\n",
    "# Define your system prompt(s).\n",
    "system_list = [\n",
    "    { \"text\": \"You are an expert media analyst. When the user provides you with a video, provide 3 potential video titles in Korean.\" }\n",
    "]\n",
    "\n",
    "# Define a \"user\" message including both the image and a text prompt.\n",
    "message_list = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"video\": {\n",
    "                    \"format\": \"mp4\",\n",
    "                    \"source\": {\"bytes\": base64_string},\n",
    "                }\n",
    "            },\n",
    "            {\"text\": \"이 영상에 어울리는 제목을 만들어주세요.\"},\n",
    "        ],\n",
    "    }\n",
    "]\n",
    "\n",
    "# Configure the inference parameters.\n",
    "inf_params = {\"max_new_tokens\": 300, \"top_p\": 0.1, \"top_k\": 20, \"temperature\": 0.3}\n",
    "\n",
    "native_request = {\n",
    "    \"messages\": message_list,\n",
    "    \"system\": system_list,\n",
    "    \"inferenceConfig\": inf_params,\n",
    "}\n",
    "\n",
    "# Invoke the model and extract the response body.\n",
    "response = client.invoke_model(modelId=PRO_MODEL_ID, body=json.dumps(native_request))\n",
    "model_response = json.loads(response[\"body\"].read())\n",
    "\n",
    "# Pretty print the response JSON.\n",
    "print(\"[Full Response]\")\n",
    "print(json.dumps(model_response, indent=2))\n",
    "\n",
    "# Print the text content for easy readability.\n",
    "content_text = model_response[\"output\"][\"message\"][\"content\"][0][\"text\"]\n",
    "print(\"\\n[Response Content Text]\")\n",
    "print(content_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a29615-4915-4475-8511-fff08eeb97ad",
   "metadata": {},
   "source": [
    "### S3 경로를 사용한 비디오 이해"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e09acca-c6a1-4c76-b9c7-65787e93896a",
   "metadata": {},
   "source": [
    "#### 아래의 S3 URI를 비디오가 위치한 S3 URI로 교체하세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2b1bc4-3e98-46ed-ab0c-a68e90f7c541",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define your system prompt(s).\n",
    "system_list = [\n",
    "    { \"text\": \"You are an expert media analyst. When the user provides you with a video, provide 3 potential video titles\" }\n",
    "]\n",
    "\n",
    "# Define a \"user\" message including both the image and a text prompt.\n",
    "message_list = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"video\": {\n",
    "                    \"format\": \"mp4\",\n",
    "                    \"source\": {\n",
    "                        \"s3Location\": {\n",
    "                            # Replace the S3 URI\n",
    "                            \"uri\": \"s3://demo-bucket/the-sea.mp4\"\n",
    "                        }\n",
    "                    },\n",
    "                }\n",
    "            },\n",
    "            {\"text\": \"Provide video titles for this clip.\"},\n",
    "        ],\n",
    "    }\n",
    "]\n",
    "\n",
    "# Configure the inference parameters.\n",
    "inf_params = {\"max_new_tokens\": 300, \"top_p\": 0.1, \"top_k\": 20, \"temperature\": 0.3}\n",
    "\n",
    "native_request = {\n",
    "    \"schemaVersion\": \"messages-v1\",\n",
    "    \"messages\": message_list,\n",
    "    \"system\": system_list,\n",
    "    \"inferenceConfig\": inf_params,\n",
    "}\n",
    "\n",
    "# Invoke the model and extract the response body.\n",
    "response = client.invoke_model(modelId=LITE_MODEL_ID, body=json.dumps(native_request))\n",
    "model_response = json.loads(response[\"body\"].read())\n",
    "\n",
    "# Pretty print the response JSON.\n",
    "print(\"[Full Response]\")\n",
    "print(json.dumps(model_response, indent=2))\n",
    "\n",
    "# Print the text content for easy readability.\n",
    "content_text = model_response[\"output\"][\"message\"][\"content\"][0][\"text\"]\n",
    "print(\"\\n[Response Content Text]\")\n",
    "print(content_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
